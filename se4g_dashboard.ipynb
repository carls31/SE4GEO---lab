{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://discomap.eea.europa.eu/map/fme/latest/files.txt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from se4g_helper import download_request\n",
    "# website containing countries & pollutants list\n",
    "'''https://discomap.eea.europa.eu/map/fme/latest/files.txt'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set countries to be downloaded\n",
    "COUNTRIES = ['AD','AT','BA','BE','BG','CH','CY','CZ','DE','DK','EE','ES','FI','SE']\n",
    "# Set pollutant to be downloaded\n",
    "POLLUTANTS = ['SO2','CO','O3','PM25','PM10']\n",
    "#CY_PM10\n",
    "#FI_CO.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "22-05-2023_14_23_39 directory created\n",
      "Downloading: http://discomap.eea.europa.eu/map/fme/latest/AD_SO2.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\22-05-2023_14_23_39\\\\AD_SO2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Download and get the dataframe file name\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m file_name \u001b[39m=\u001b[39m download_request(COUNTRIES, POLLUTANTS)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(file_name)\n",
      "File \u001b[1;32mc:\\Users\\Utente\\Documents\\GitHub\\SE4GEO-Lab\\se4g_helper.py:34\u001b[0m, in \u001b[0;36mdownload_request\u001b[1;34m(countries, pollutants, folder_out)\u001b[0m\n\u001b[0;32m     32\u001b[0m full_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder_out,\u001b[39mdir\u001b[39m, fileName)\n\u001b[0;32m     33\u001b[0m \u001b[39m#full_file = os.path.join(folder_out, fileName)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(full_file, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     35\u001b[0m output\u001b[39m.\u001b[39mwrite(file)\n\u001b[0;32m     36\u001b[0m output\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\22-05-2023_14_23_39\\\\AD_SO2.csv'"
     ]
    }
   ],
   "source": [
    "# Download and get the dataframe file name\n",
    "file_name = download_request(COUNTRIES, POLLUTANTS)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the folder where the dataframe file is located\n",
    "folder_out = 'data'\n",
    "full_file = os.path.join(folder_out, file_name)\n",
    "# Read the file\n",
    "df = pd.read_csv(full_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = ['station_code', \n",
    "              'station_name', \n",
    "              'station_altitude', \n",
    "              'network_countrycode', \n",
    "              'pollutant', \n",
    "              'value_datetime_begin',\n",
    "              'value_datetime_end',\n",
    "              'value_datetime_updated',\n",
    "              'value_numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è ok\n"
     ]
    }
   ],
   "source": [
    "file_prova = 'FI_CO_NONFUNZIA'\n",
    "if file_prova != 'FI_CO.csv' and file_prova != 'FI_O_NONFUNZIA':\n",
    "    print('è ok')\n",
    "else:\n",
    "    print('non funziona')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all = pd.DataFrame()\n",
    "dfs = []\n",
    "for country in COUNTRIES:\n",
    "    for pollutant in POLLUTANTS:\n",
    "        \n",
    "        fileName = \"%s_%s.csv\" % (country, pollutant)\n",
    "        if fileName != \"FI_CO.csv\" and fileName != \"CY_PM10.csv\":\n",
    "            df_temp = pd.read_csv(\"data/\"+fileName)\n",
    "            #data = df_temp[df_columns]\n",
    "            dfs.append(df_temp[df_columns])\n",
    "            #df_all = pd.DataFrame(data)\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_altitude</th>\n",
       "      <th>network_countrycode</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>value_datetime_begin</th>\n",
       "      <th>value_datetime_end</th>\n",
       "      <th>value_datetime_updated</th>\n",
       "      <th>value_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD0942A</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>SO2</td>\n",
       "      <td>2023-05-20 17:00:00+01:00</td>\n",
       "      <td>2023-05-20 18:00:00+01:00</td>\n",
       "      <td>+01:00</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD0942A</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>SO2</td>\n",
       "      <td>2023-05-20 18:00:00+01:00</td>\n",
       "      <td>2023-05-20 19:00:00+01:00</td>\n",
       "      <td>+01:00</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD0942A</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>SO2</td>\n",
       "      <td>2023-05-20 19:00:00+01:00</td>\n",
       "      <td>2023-05-20 20:00:00+01:00</td>\n",
       "      <td>+01:00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD0942A</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>SO2</td>\n",
       "      <td>2023-05-20 20:00:00+01:00</td>\n",
       "      <td>2023-05-20 21:00:00+01:00</td>\n",
       "      <td>+01:00</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD0942A</td>\n",
       "      <td>Escaldes-Engordany</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>AD</td>\n",
       "      <td>SO2</td>\n",
       "      <td>2023-05-20 21:00:00+01:00</td>\n",
       "      <td>2023-05-20 22:00:00+01:00</td>\n",
       "      <td>+01:00</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_code        station_name  station_altitude network_countrycode  \\\n",
       "0      AD0942A  Escaldes-Engordany            1080.0                  AD   \n",
       "1      AD0942A  Escaldes-Engordany            1080.0                  AD   \n",
       "2      AD0942A  Escaldes-Engordany            1080.0                  AD   \n",
       "3      AD0942A  Escaldes-Engordany            1080.0                  AD   \n",
       "4      AD0942A  Escaldes-Engordany            1080.0                  AD   \n",
       "\n",
       "  pollutant       value_datetime_begin         value_datetime_end  \\\n",
       "0       SO2  2023-05-20 17:00:00+01:00  2023-05-20 18:00:00+01:00   \n",
       "1       SO2  2023-05-20 18:00:00+01:00  2023-05-20 19:00:00+01:00   \n",
       "2       SO2  2023-05-20 19:00:00+01:00  2023-05-20 20:00:00+01:00   \n",
       "3       SO2  2023-05-20 20:00:00+01:00  2023-05-20 21:00:00+01:00   \n",
       "4       SO2  2023-05-20 21:00:00+01:00  2023-05-20 22:00:00+01:00   \n",
       "\n",
       "  value_datetime_updated  value_numeric  \n",
       "0                 +01:00            0.1  \n",
       "1                 +01:00            0.6  \n",
       "2                 +01:00            0.5  \n",
       "3                 +01:00            0.3  \n",
       "4                 +01:00            0.1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(\"data/\"+fileName)\n",
    "'''print(os.path.isfile(\"data/\"+fileName))\n",
    "print('fileName', fileName)\n",
    "dfs'''\n",
    "pd.read_csv(\"data/CY_PM10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'login_required' from 'se4g_utils' (c:\\Users\\Utente\\Documents\\GitHub\\SE4GEO-Lab\\se4g_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mse4g_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m login_required\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWelcome to the application!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPlease log in to continue.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'login_required' from 'se4g_utils' (c:\\Users\\Utente\\Documents\\GitHub\\SE4GEO-Lab\\se4g_utils.py)"
     ]
    }
   ],
   "source": [
    "from se4g_helper import login_required\n",
    "\n",
    "print(\"Welcome to the application!\")\n",
    "print(\"Please log in to continue.\")\n",
    "con = login_required()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now = 2023-05-22 14:31:20.135298\n",
      "22-05-2023_14_31_20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'folderout\\\\22-05-2023_14_31_20\\\\filename'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    " \n",
    "print(\"now =\", now)\n",
    "print(datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\"))\n",
    "folder_out = 'folderout'\n",
    "fileName = 'filename'\n",
    "os.path.join(folder_out,str(datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\")), fileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
