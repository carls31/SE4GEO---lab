{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import socket\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir:  c:\\Users\\Utente\\Documents\\GitHub\\SE4GEO-Lab\\db_helper\n",
      "Current working directory: c:\\Users\\Utente\\Documents\\GitHub\\SE4GEO-Lab\n"
     ]
    }
   ],
   "source": [
    "# Set the working directory\n",
    "current_dir = os.getcwd()\n",
    "print('current_dir: ',current_dir)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "print('Current working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected with  localhost\n"
     ]
    }
   ],
   "source": [
    "# Setup DB connection \n",
    "import psycopg2\n",
    "def connect_right_now():\n",
    "    ip = '192.168.30.19'\n",
    "    ip = 'localhost'\n",
    "    conn = psycopg2.connect(\n",
    "        host = ip,\n",
    "        database = \"se4g\",\n",
    "        user = \"postgres\",\n",
    "        password = \"carIs3198\"\n",
    "    )\n",
    "    print('connected with ',ip)\n",
    "    return conn\n",
    "conn = connect_right_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected with  localhost\n"
     ]
    }
   ],
   "source": [
    "'''Preferably use psycopg2 connection'''\n",
    "# 'postgresql://postgres:admin@localhost:5432/se4g23'  \n",
    "\n",
    "file = 'bin.txt'\n",
    "with open('code/'+file, 'r') as f:\n",
    "    engine = create_engine('postgresql://postgres:'+f.read()+'@'+ip+':5432/se4g') \n",
    "con = engine.connect()\n",
    "print('connected with ',ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = [\n",
    "    'VARCHAR',\n",
    "    'VARCHAR',\n",
    "    'FLOAT',\n",
    "    'CHAR(2)',\n",
    "    'VARCHAR',\n",
    "    'VARCHAR',\n",
    "    'VARCHAR',\n",
    "    'VARCHAR',\n",
    "    'FLOAT']\n",
    "\n",
    "df_columns=[\n",
    "    'station_code',\n",
    "    'station_name',\n",
    "    'station_altitude',\n",
    "    'network_countrycode',\n",
    "    'pollutant',\n",
    "    'value_datetime_begin',\n",
    "    'value_datetime_end',\n",
    "    'value_datetime_updated',\n",
    "    'value_numeric',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected with  localhost\n",
      "created\n"
     ]
    }
   ],
   "source": [
    "conn = connect_right_now()\n",
    "\n",
    "# ANGELICA'S WORK IN PROGRESS\n",
    "cur = conn.cursor()\n",
    "cur.execute('''CREATE TABLE IF NOT EXISTS station\n",
    " (station_code VARCHAR PRIMARY KEY, \n",
    " station_name TEXT,\n",
    " station_altitude FLOAT,\n",
    " network_countrycode TEXT)''')\n",
    "print('created')\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected with  localhost\n",
      "created\n"
     ]
    }
   ],
   "source": [
    "conn = connect_right_now()\n",
    "\n",
    "# ANGELICA'S WORK IN PROGRESS\n",
    "cur = conn.cursor()\n",
    "cur.execute('''CREATE TABLE IF NOT EXISTS pollutant_detection\n",
    " (station_code VARCHAR , \n",
    " pollutant TEXT, \n",
    " value_datetime_begin TEXT, \n",
    " value_datetime_end TEXT,\n",
    " value_numeric FLOAT,\n",
    " PRIMARY KEY (pollutant, station_code, value_datetime_begin))''')\n",
    "print('created')\n",
    "conn.commit()\n",
    "cur.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANGELICA'S WORK IN PROGRESS\n",
    "\n",
    "def select_country():\n",
    "    country= input(\"Enter the country name: \")\n",
    "    cur.execute(f\"SELECT * FROM station WHERE country = {country}\")\n",
    "    result = cur.fetchall()\n",
    "    if result:\n",
    "        print(\"Stations in\", country)\n",
    "        for row in result:\n",
    "            print(\"Station Code:\", row[0])\n",
    "            print(\"Station Name:\", row[1])\n",
    "            print(\"Station Local ID:\", row[2])\n",
    "            print(\"Station Altitude:\", row[3])\n",
    "            print(\"Country:\", row[4])\n",
    "            print()\n",
    "            return row[4]\n",
    "    else:\n",
    "        print(\"No stations found in\", country)\n",
    "\n",
    "# User interaction: select a pollutant\n",
    "country=select_country()\n",
    "\n",
    "# Create the RadioButtons widget\n",
    "RButtons = widgets.RadioButtons(\n",
    "    options=country,\n",
    "    description='Select Country:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Define a function to handle the selection event\n",
    "def handle_selection(change):\n",
    "    selected_country = change['new']\n",
    "    # Do something with the selected pollutant\n",
    "    print('Selected Country:', selected_country)\n",
    "\n",
    "# Register the event handler function\n",
    "RButtons.observe(handle_selection, 'value')\n",
    "\n",
    "# Display the RadioButtons widget\n",
    "RButtons\n",
    "\n",
    "\n",
    "# Close the connection\n",
    "cur.close()\n",
    "\n",
    "def select_pollutant():\n",
    "    pollutant = input(\"Enter the pollutant name: \")\n",
    "    cur.execute(f\"SELECT * FROM pollution_data WHERE name_pollutant = {pollutant}\")\n",
    "    result = cur.fetchall()\n",
    "    if result:\n",
    "        print(\"Pollution data for\", pollutant)\n",
    "        for row in result:\n",
    "            print(\"Station Code:\", row[0])\n",
    "            print(\"Pollutant:\", row[1])\n",
    "            print(\"Data Time Begin:\", row[2])\n",
    "            print(\"Data Time End:\", row[3])\n",
    "            print(\"Data Time Update:\", row[4])\n",
    "            print(\"Value:\", row[5])\n",
    "            print()\n",
    "            return row[1]\n",
    "    else:\n",
    "        print(\"No pollution data found for\", pollutant)\n",
    "           \n",
    "# User interaction: select a pollutant\n",
    "pollutant_names=select_pollutant()\n",
    "\n",
    "# Create the RadioButtons widget\n",
    "RButtons = widgets.RadioButtons(\n",
    "    options=pollutant_names,\n",
    "    description='Select Pollutant:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Define a function to handle the selection event\n",
    "def handle_selection(change):\n",
    "    selected_pollutant = change['new']\n",
    "    # Do something with the selected pollutant\n",
    "    print('Selected Pollutant:', selected_pollutant)\n",
    "\n",
    "# Register the event handler function\n",
    "RButtons.observe(handle_selection, 'value')\n",
    "\n",
    "# Display the RadioButtons widget\n",
    "RButtons\n",
    "\n",
    "\n",
    "# Close the connection\n",
    "cur.close()\n",
    "\n",
    "#MOLTO PROVVISORIA L'ULTIMA PARTE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table creation \n",
    "iLory x Angie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_exists(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE LOWER(table_name) = LOWER('{table_name}'))\")\n",
    "    exists = cur.fetchone()[0]\n",
    "    cur.close()\n",
    "    return exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE custom_table1 (station_code VARCHAR PRIMARY KEY, station_name VARCHAR, station_altitude FLOAT, network_countrycode CHAR(2), pollutant VARCHAR, value_datetime_begin VARCHAR, value_datetime_end VARCHAR, value_datetime_updated VARCHAR, value_numeric FLOAT)\n",
      "created\n"
     ]
    }
   ],
   "source": [
    "# SELECT THE NAME OF THE CUSTOM TABLE\n",
    "table_name='se4g_dashboard2' \n",
    "\n",
    "# INSERT HERE THE TYPE OF EACH COLUMN OF THE CUSTOM TABLE\n",
    "data_type = [\n",
    "            'VARCHAR',\n",
    "            'VARCHAR',\n",
    "            'FLOAT',\n",
    "            'CHAR(2)',\n",
    "            'VARCHAR',\n",
    "            'VARCHAR',\n",
    "            'VARCHAR',\n",
    "            'VARCHAR',\n",
    "            'FLOAT',\n",
    "            ]\n",
    "\n",
    "# DEFINE HERE THE NAME OF EACH COLUMN OF THE CUSTOM TABLE\n",
    "df_columns=[\n",
    "            'station_code',\n",
    "            'station_name',\n",
    "            'station_altitude',\n",
    "            'network_countrycode',\n",
    "            'pollutant',\n",
    "            'value_datetime_begin',\n",
    "            'value_datetime_end',\n",
    "            'value_datetime_updated',\n",
    "            'value_numeric',\n",
    "             ]\n",
    "\n",
    "# CREATE THE CUSTOM TABLE\n",
    "def create_custom_TABLE(table_name, conn,\n",
    "                        data_type = ['VARCHAR', 'VARCHAR', 'FLOAT', \n",
    "                                     'CHAR(2)', 'VARCHAR', 'VARCHAR', \n",
    "                                     'VARCHAR', 'VARCHAR', 'FLOAT'],\n",
    "                        df_columns= ['station_code', 'station_name', 'station_altitude', \n",
    "                                     'network_countrycode', 'pollutant', 'value_datetime_begin', \n",
    "                                     'value_datetime_end', 'value_datetime_updated', 'value_numeric'],\n",
    "                                        ):\n",
    "\n",
    "    if not table_exists(table_name, conn):\n",
    "\n",
    "        cur = conn.cursor()\n",
    "        # In this way we add 'station_code' as PRIMARY KEY \n",
    "        column_definitions = [f\"{column} {data_type[i]}\" if column != 'station_code' else f\"{column} {data_type[i]} PRIMARY KEY\" for i, column in enumerate(df_columns)]\n",
    "        #column_definitions = [f\"{column} {data_type[i]}\" for i, column in enumerate(df_columns)] # old code that does note assign the PRIMARY KEY\n",
    "        \n",
    "        create_table_statement = f\"CREATE TABLE {table_name} ({', '.join(column_definitions)})\"\n",
    "        print(create_table_statement)\n",
    "\n",
    "        cur.execute(create_table_statement)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        print('created')\n",
    "    else:\n",
    "        exists = table_exists(table_name,conn)\n",
    "        print(f\"The table '{table_name}' exists: {exists}\")\n",
    "\n",
    "create_custom_TABLE('custom_table1', conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU CAN USE THIS FUNCTION TO COPY A TABLE INSIDE ANOTHER NEW TABLE e.g. FOR BACKUP PURPOSE (BEFORE DOING A MESS FOR EXAMPLE)\n",
    "def copy_table_data(connection, source_table_name, destination_table_name):\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    # Truncate the destination table to remove existing data (optional)\n",
    "    cursor.execute(f\"TRUNCATE TABLE {destination_table_name};\")\n",
    "    \n",
    "    # Generate the SQL statement to copy data from the source table to the destination table\n",
    "    copy_data_query = f\"INSERT INTO {destination_table_name} SELECT * FROM {source_table_name};\"\n",
    "    \n",
    "    # Execute the COPY command\n",
    "    cursor.execute(copy_data_query)\n",
    "    \n",
    "    # Commit the changes\n",
    "    connection.commit()\n",
    "    \n",
    "    # Close the cursor\n",
    "    cursor.close()\n",
    "\n",
    "# Specify the names of the source table and destination table\n",
    "source_table_name = 'se4g_TABLE'\n",
    "destination_table_name = 'se4g_TABLE_COPY'\n",
    "\n",
    "# EXECUTE THE FUNCTION\n",
    "# Call the function to copy the data from the source table to the destination table\n",
    "copy_table_data(conn, source_table_name, destination_table_name)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect_right_now()\n",
    "\n",
    "def print_table_data(connection, \n",
    "                    source_table_name, \n",
    "                    columns = [ 'station_code' , \n",
    "                                'station_name', \n",
    "                                'station_altitude', \n",
    "                                'network_countrycode'\n",
    "                                ]\n",
    "                    ):\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    # Truncate the destination table to remove existing data (optional)\n",
    "    cursor.execute(f\"TRUNCATE TABLE {destination_table_name};\")\n",
    "    \n",
    "    # Generate the SQL statement to copy data from the source table to the destination table\n",
    "    copy_data_query = f\"SELECT DISTINCT * FROM {source_table_name};\"\n",
    "    \n",
    "    # Execute the COPY command\n",
    "    cursor.execute(copy_data_query)\n",
    "\n",
    "    # Fetch all the rows\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    # Create a pandas DataFrame from the fetched rows\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    # Group the DataFrame by 'station_code' and filter the groups with more than one unique combination of values\n",
    "    #filtered_df = df.groupby('station_code').filter(lambda x: len(x.drop_duplicates(subset=['station_name', 'station_altitude', 'network_countrycode'])) > 1)\n",
    "\n",
    "    # Print the filtered DataFrame\n",
    "    print(df)\n",
    "\n",
    "    # Close the cursor\n",
    "    cursor.close()\n",
    "\n",
    "# Specify the names of the source table and destination table\n",
    "table_name = 'station'\n",
    "\n",
    "print_table_data(conn, table_name)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected with  localhost\n",
      "Table station filled\n"
     ]
    }
   ],
   "source": [
    "conn = connect_right_now()\n",
    "\n",
    "\n",
    "def fill_table_data(connection,\n",
    "                    source_table_name,\n",
    "                    destination_table_name,\n",
    "                    columns=['station_code',\n",
    "                             'station_name',\n",
    "                             'station_altitude',\n",
    "                             'network_countrycode']\n",
    "                    ):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Truncate the destination table to remove existing data (optional)\n",
    "    cursor.execute(f\"TRUNCATE TABLE {destination_table_name};\")\n",
    "\n",
    "    # Create a unique index on 'station_code' column\n",
    "    cursor.execute(f\"CREATE UNIQUE INDEX idx_unique_station_code ON {destination_table_name} (station_code);\")\n",
    "\n",
    "    # Generate the SQL statement to copy data from the source table to the destination table\n",
    "    copy_data_query = f\"INSERT INTO {destination_table_name} ({', '.join(columns)}) \" \\\n",
    "                      f\"SELECT DISTINCT ON (station_code) {', '.join(columns)} FROM {source_table_name};\"\n",
    "\n",
    "    # Execute the COPY command\n",
    "    cursor.execute(copy_data_query)\n",
    "\n",
    "    # Commit the changes\n",
    "    connection.commit()\n",
    "    print(f'Table {destination_table_name} filled')\n",
    "\n",
    "    # Close the cursor\n",
    "    cursor.close()\n",
    "\n",
    "fill_table_data(conn, source_table_name, destination_table_name)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected with  localhost\n",
      "Table pollutant_detection filled\n"
     ]
    }
   ],
   "source": [
    "conn = connect_right_now()\n",
    "\n",
    "\n",
    "def fill_table_data(connection,\n",
    "                    source_table_name,\n",
    "                    destination_table_name,\n",
    "                    columns=['station_code',\n",
    "                             'pollutant',\n",
    "                             'value_datetime_begin',\n",
    "                             'value_datetime_end',\n",
    "                             'value_numeric']\n",
    "                    ):\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Truncate the destination table to remove existing data (optional)\n",
    "    cursor.execute(f\"TRUNCATE TABLE {destination_table_name};\")\n",
    "\n",
    "    # Create a unique index on 'station_code' column\n",
    "    cursor.execute(f\"CREATE UNIQUE INDEX idx_unique_p_s_v ON {destination_table_name} (pollutant, station_code, value_datetime_begin);\")\n",
    "\n",
    "    # Generate the SQL statement to copy data from the source table to the destination table\n",
    "    copy_data_query = f\"INSERT INTO {destination_table_name} ({', '.join(columns)}) \" \\\n",
    "                      f\"SELECT DISTINCT ON (pollutant, station_code, value_datetime_begin) {', '.join(columns)} FROM {source_table_name};\"\n",
    "\n",
    "    # Execute the COPY command\n",
    "    cursor.execute(copy_data_query)\n",
    "\n",
    "    # Commit the changes\n",
    "    connection.commit()\n",
    "    print(f'Table {destination_table_name} filled')\n",
    "\n",
    "    # Close the cursor\n",
    "    cursor.close()\n",
    "\n",
    "source_table_name = 'se4g_pollution_db'\n",
    "destination_table_name = 'pollutant_detection'\n",
    "\n",
    "fill_table_data(conn, source_table_name, destination_table_name)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(table_name, rows, conn, columns):\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Generate the SQL INSERT statement with specified columns\n",
    "    insert_statement = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))})\"\n",
    "\n",
    "    rows = [\n",
    "        tuple(\n",
    "            val.strftime('%Y-%m-%d %H:%M:%S%z') if isinstance(val, datetime) else val\n",
    "            if val != '' else None  # Replace empty string with None for double precision columns\n",
    "            for val in row\n",
    "        )\n",
    "        for row in rows\n",
    "    ]\n",
    "\n",
    "    # Execute the INSERT statement for each row\n",
    "    cur.executemany(insert_statement, rows)\n",
    "\n",
    "    # Commit the changes and close the cursor\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "\n",
    "\n",
    "def table_exists(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE LOWER(table_name) = LOWER('{table_name}'))\")\n",
    "    exists = cur.fetchone()[0]\n",
    "    cur.close()\n",
    "    return exists\n",
    "\n",
    "\n",
    "# Update DATABASE\n",
    "def update_DB(new_rows, connection, table_name='se4g_pollution_DB', columns=None):\n",
    "    cur = connection.cursor()\n",
    "\n",
    "    # Generate the SQL SELECT statement\n",
    "    select_statement = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "    # Execute the SELECT statement\n",
    "    cur.execute(select_statement)\n",
    "\n",
    "    # Fetch all the results\n",
    "    results = cur.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    all_columns = [desc[0] for desc in cur.description]\n",
    "\n",
    "    # Use all columns if specific columns are not provided\n",
    "    if not columns:\n",
    "        columns = all_columns\n",
    "\n",
    "    # Convert the results to a set of tuples for efficient comparison\n",
    "    existing_data = {tuple(row) for row in results}\n",
    "\n",
    "    # Filter new_rows to only include rows not already present in the table\n",
    "    filtered_rows = [row for row in new_rows if tuple(row) not in existing_data]\n",
    "\n",
    "    if len(filtered_rows) == 0:\n",
    "        print(\"Nothing to update inside database\", table_name)\n",
    "    else:\n",
    "\n",
    "        # Execute the INSERT statement to add the filtered rows\n",
    "        insert_data(table_name, filtered_rows, connection, columns)\n",
    "        print(\"Database\", table_name, \"updated successfully\")\n",
    "\n",
    "    # Close the cursor\n",
    "    cur.close()\n",
    "\n",
    "    return filtered_rows\n",
    "\n",
    "\n",
    "# Download and get the dataframe file name\n",
    "def update_table(\n",
    "    connection,\n",
    "    df_columns=['station_code',\n",
    "                'pollutant',\n",
    "                'value_datetime_begin',\n",
    "                'value_datetime_end',\n",
    "                'value_numeric'],\n",
    "    table_name='pollutant_detection'\n",
    "):\n",
    "    print('-----------------------------------------------------------------------')\n",
    "    # Set download url\n",
    "    # https://discomap.eea.europa.eu/map/fme/AirQualityUTDExport.htm\n",
    "    ServiceUrl = \"http://discomap.eea.europa.eu/map/fme/latest\"\n",
    "\n",
    "    # Create a cursor\n",
    "    cur = connection.cursor()\n",
    "\n",
    "    # Check if the table exists, create it if it doesn't\n",
    "    if not table_exists(table_name, connection):\n",
    "        fill_table_data(connection, source_table_name, destination_table_name)\n",
    "\n",
    "    updated_rows = update_DB(new_rows, connection, table_name, df_columns)\n",
    "\n",
    "                #return updated_rows\n",
    "\n",
    "    # Close the cursor \n",
    "    cur.close()\n",
    "#conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
