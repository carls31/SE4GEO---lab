{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir:  c:\\Users\\Utente\\Documents\\GitHub\\SE4GEO-Lab\\db_helper\n",
      "Current working directory: c:\\Users\\Utente\\Documents\\GitHub\\SE4GEO-Lab\n"
     ]
    }
   ],
   "source": [
    "# Set the working directory\n",
    "current_dir = os.getcwd()\n",
    "print('current_dir: ',current_dir)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "print('Current working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from se4g_helper import build_dataframe, update_dataset\n",
    "\n",
    "df_columns=['station_code', 'station_name', 'station_altitude', 'network_countrycode', 'pollutant', 'value_datetime_begin',\n",
    "            'value_datetime_end', 'value_datetime_updated', 'value_numeric', 'samplingpoint_x', 'samplingpoint_y'\n",
    "            ]\n",
    "data_type = ['VARCHAR', 'VARCHAR', 'FLOAT', 'CHAR(2)', 'VARCHAR', 'VARCHAR',\n",
    "             'VARCHAR', 'VARCHAR', 'FLOAT', 'FLOAT', 'FLOAT'\n",
    "             ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create se4g_pollution_main.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"se4g_pollution_dataset.csv\" # execution time: 1m23s -> 1m51s\n",
    "folder_out = 'data_prova'\n",
    "\n",
    "\n",
    "columns = df_columns\n",
    "\n",
    "data_type = data_type\n",
    "\n",
    "\n",
    "for item_name in os.listdir(folder_out):\n",
    "    item_path = os.path.join(folder_out, item_name)\n",
    "\n",
    "    if os.path.isdir(item_path):\n",
    "        new_df = build_dataframe(item_name, folder_out = folder_out )\n",
    "\n",
    "        update_dataset(new_df, folder_out = folder_out, fileName = \"se4g_pollution_main.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create se4g_pollution_dashboard.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset  data_prova\\se4g_pollution_main.csv  created\n"
     ]
    }
   ],
   "source": [
    "source_df = \"se4g_pollution_main.csv\" # execution time: 1m23s -> 1m51s\n",
    "folder_out = 'data_prova'\n",
    "full_path = os.path.join(folder_out, source_df)\n",
    "\n",
    "columns = ['pollutant', 'country', 'month_day', 'value_numeric_mean']\n",
    "\n",
    "country = {'AD': 'Andorra', 'SE': 'Sweden', 'DE': 'Germany', 'CY': 'Undefined', 'BE': 'Belgium',\n",
    "           'FI': 'Finland', 'ES': 'Spain', 'CZ': 'Czech Republic', 'BG': 'Bulgaria', 'BA': 'Bosnia and Herzegovina',\n",
    "           'EE': 'Estonia', 'CH': 'Switzerland', 'AT': 'Austria', 'DK': 'Denmark'}\n",
    "   \n",
    "if os.path.isfile(full_path):\n",
    "    dashboard_df = pd.read_csv(full_path)\n",
    "    # Convert 'value_datetime_end' to datetime objects and extract the day\n",
    "    datetime_objects = dashboard_df['value_datetime_end'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S%z'))\n",
    "    \n",
    "    dashboard_df['month_day'] = datetime_objects.apply(lambda x: x.strftime('%m%d'))\n",
    "    \n",
    "    dashboard_df['value_datetime_begin'] = pd.to_datetime(dashboard_df['value_datetime_begin']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Compute daily mean of 'value_numeric' for each 'pollutant' and 'network_countrycode'\n",
    "    daily_mean = dashboard_df.groupby(['pollutant', 'network_countrycode', 'month_day'])['value_numeric'].mean().reset_index()\n",
    "    \n",
    "    # Merge the daily mean back to the original dataframe\n",
    "    dashboard_df = dashboard_df.merge(daily_mean, on=['pollutant', 'network_countrycode', 'month_day'], suffixes=('', '_mean'))    \n",
    "\n",
    "    dashboard_df['country'] = dashboard_df['network_countrycode'].map(country)\n",
    "    dashboard_df = dashboard_df[columns].copy()\n",
    "    dashboard_df = dashboard_df[dashboard_df['pollutant'] != 'O3']\n",
    "    dashboard_df = dashboard_df.drop_duplicates().reset_index(drop=True)\n",
    "    dashboard_df = dashboard_df.sort_values('month_day')\n",
    "\n",
    "    dashboard_df.to_csv('data_prova/se4g_dashboard_dataset.csv', index=False)\n",
    "    print(\"Dataset \",full_path,\" created\")\n",
    "    \n",
    "else: \n",
    "        print(\"Dataset \",full_path,\" does not exist\")\n",
    "        print(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check empty csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data_prova/31-05-2023_09_15_34/ES_PM10.csv'\n",
    "file_path = 'data_prova/31-05-2023_10_53_20/ES_PM10.csv'\n",
    "print(file_path)\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    print(file)\n",
    "    first_line = file.readline().strip()\n",
    "\n",
    "if not first_line.startswith('<!DOCTYPE html'): \n",
    "    #print(fileName,'exist')\n",
    "\n",
    "    df_temp = pd.read_csv(file_path)\n",
    "    print(df_temp['network_countrycode'].head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download reques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def download_request(COUNTRIES= 'ES',\n",
    "                        POLLUTANTS= 'PM10',\n",
    "                        folder_out = 'data_prova'):\n",
    "    print ('-----------------------------------------------------------------------')\n",
    "    # Set download url\n",
    "    # https://discomap.eea.europa.eu/map/fme/AirQualityUTDExport.htm\n",
    "    ServiceUrl = \"http://discomap.eea.europa.eu/map/fme/latest\"\n",
    "\n",
    "\n",
    "    dir = datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\")\n",
    "\n",
    "    if not os.path.exists(os.path.join(folder_out, dir)):\n",
    "        if not os.path.exists(folder_out):\n",
    "            os.mkdir(folder_out)\n",
    "        os.mkdir(os.path.join(folder_out, dir))\n",
    "        print(dir,'directory created')\n",
    "        \n",
    "    for country in COUNTRIES:\n",
    "        for pollutant in POLLUTANTS:\n",
    "            fileName = \"%s_%s.csv\" % (country, pollutant)\n",
    "            downloadFile = '%s/%s_%s.csv' % (ServiceUrl, country, pollutant)\n",
    "            #Download and save to local path\n",
    "            print('Downloading: %s' % downloadFile )\n",
    "\n",
    "            file = requests.get(downloadFile).content\n",
    "            full_file = os.path.join(folder_out, dir, fileName)\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "            '''with codecs.open(full_file, 'r', encoding='utf-8-sig') as file:\n",
    "                content = file.read()'''\n",
    "\n",
    "            # Modify the content as needed\n",
    "            with codecs.open(full_file, 'w', encoding='utf-8') as output:\n",
    "                output.write(file)\n",
    "\n",
    "\n",
    "\n",
    "            '''output = open(full_file, 'wb')\n",
    "            output.write(file)\n",
    "            output.close()'''\n",
    "            print ('Saved locally as: %s ' % full_file)\n",
    "            print ('-----')\n",
    "    print ('Download finished')\n",
    "    return dir\n",
    "\n",
    "dirr = download_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_request(COUNTRIES=['ES'], POLLUTANTS=['PM10'], folder_out='data_prova'):\n",
    "    print('-----------------------------------------------------------------------')\n",
    "    # Set download url\n",
    "    # https://discomap.eea.europa.eu/map/fme/AirQualityUTDExport.htm\n",
    "    ServiceUrl = \"http://discomap.eea.europa.eu/map/fme/latest\"\n",
    "\n",
    "    dir = datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\")\n",
    "\n",
    "    if not os.path.exists(os.path.join(folder_out, dir)):\n",
    "        if not os.path.exists(folder_out):\n",
    "            os.mkdir(folder_out)\n",
    "        os.mkdir(os.path.join(folder_out, dir))\n",
    "        print(dir, 'directory created')\n",
    "\n",
    "    for country in COUNTRIES:\n",
    "        for pollutant in POLLUTANTS:\n",
    "            fileName = \"%s_%s.csv\" % (country, pollutant)\n",
    "            downloadFile = '%s/%s_%s.csv' % (ServiceUrl, country, pollutant)\n",
    "            # Download and save to local path\n",
    "            print('Downloading: %s' % downloadFile)\n",
    "\n",
    "            file_content = requests.get(downloadFile).content\n",
    "            file_content_str = file_content.decode('utf-8-sig')\n",
    "\n",
    "            full_file = os.path.join(folder_out, dir, fileName)\n",
    "\n",
    "            with open(full_file, 'w', encoding='utf-8') as output:\n",
    "                output.write(file_content_str)\n",
    "\n",
    "            print('Saved locally as: %s ' % full_file)\n",
    "            print('-----')\n",
    "    print('Download finished')\n",
    "    return dir\n",
    "\n",
    "dirr = download_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_request(COUNTRIES=['ES'], POLLUTANTS=['PM10'], folder_out='data_prova'):\n",
    "    print('-----------------------------------------------------------------------')\n",
    "    # Set download url\n",
    "    # https://discomap.eea.europa.eu/map/fme/AirQualityUTDExport.htm\n",
    "    ServiceUrl = \"http://discomap.eea.europa.eu/map/fme/latest\"\n",
    "\n",
    "    dir = datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\")\n",
    "\n",
    "    if not os.path.exists(os.path.join(folder_out, dir)):\n",
    "        if not os.path.exists(folder_out):\n",
    "            os.mkdir(folder_out)\n",
    "        os.mkdir(os.path.join(folder_out, dir))\n",
    "        print(dir, 'directory created')\n",
    "\n",
    "    for country in COUNTRIES:\n",
    "        for pollutant in POLLUTANTS:\n",
    "            fileName = \"%s_%s.csv\" % (country, pollutant)\n",
    "            downloadFile = '%s/%s_%s.csv' % (ServiceUrl, country, pollutant)\n",
    "            # Download and save to local path\n",
    "            print('Downloading: %s' % downloadFile)\n",
    "\n",
    "            file_content = requests.get(downloadFile).content\n",
    "            file_content_str = file_content.decode('utf-8-sig')\n",
    "\n",
    "            full_file = os.path.join(folder_out, dir, fileName)\n",
    "\n",
    "            with codecs.open(full_file, 'w', encoding='utf-8') as output:\n",
    "                output.write(file_content_str)\n",
    "\n",
    "            print('Saved locally as: %s ' % full_file)\n",
    "            print('-----')\n",
    "    print('Download finished')\n",
    "    return dir\n",
    "\n",
    "dirr = download_request()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
