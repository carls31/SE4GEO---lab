{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir:  c:\\Users\\Utente\\Documents\\GitHub\\SE4GEO-Lab\\db_helper\n",
      "Current working directory: c:\\Users\\Utente\\Documents\\GitHub\\SE4GEO-Lab\n"
     ]
    }
   ],
   "source": [
    "# Set the working directory\n",
    "current_dir = os.getcwd()\n",
    "print('current_dir: ',current_dir)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "print('Current working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"se4g_dashboard_dataset.csv\"\n",
    "folder_out = 'data_prova'\n",
    "full_path = os.path.join(folder_out, fileName)\n",
    "\n",
    "country = {'AD': 'Andorra', \n",
    "        'SE':'Sweden', \n",
    "        'DE':'Germany', \n",
    "        'CY':'Undefined', \n",
    "        'BE':'Belgium', \n",
    "        'FI':'Finland', \n",
    "        'ES':'Spain', \n",
    "        'CZ':'Czech Republic', \n",
    "        'BG':'Bulgaria', \n",
    "        'BA':'Bosnia and Herzegovina', \n",
    "        'EE':'Estonia', \n",
    "        'CH':'Switzerland',\n",
    "        'AT':'Austria', \n",
    "        'DK':'Denmark'}\n",
    "\n",
    "if os.path.isfile(full_path):\n",
    "    dashboard_df = pd.read_csv(full_path)\n",
    "    # Convert 'value_datetime_end' to datetime objects and extract the day\n",
    "    datetime_objects = dashboard_df['value_datetime_end'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S%z'))\n",
    "\n",
    "    dashboard_df['month_day'] = datetime_objects.apply(lambda x: x.strftime('%m%d')).astype('int64')\n",
    "    \n",
    "    # Compute daily mean of 'value_numeric' for each 'pollutant' and 'network_countrycode'\n",
    "    daily_mean = dashboard_df.groupby(['pollutant', 'network_countrycode', 'day'])['value_numeric'].mean().reset_index()\n",
    "    \n",
    "    # Merge the daily mean back to the original dataframe\n",
    "    dashboard_df = dashboard_df.merge(daily_mean, on=['pollutant', 'network_countrycode', 'day'], suffixes=('', '_mean'))    \n",
    "\n",
    "    dashboard_df['country'] = dashboard_df['network_countrycode'].map(country)\n",
    "    dashboard_df = dashboard_df[['pollutant', 'country', 'month_day', 'value_numeric_mean','value_datetime_begin']].copy()\n",
    "\n",
    "    dashboard_df = dashboard_df.drop_duplicates().reset_index(drop=True)\n",
    "    dashboard_df = dashboard_df.sort_values('month_day')\n",
    "    dashboard_df.to_csv('data_prova/se4g_dashboard_dataset_prova.csv', index=False)\n",
    "    \n",
    "else: \n",
    "        print(\"Dataset \",full_path,\" does not exist\")\n",
    "        print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_prova/31-05-2023_10_53_20/ES_PM10.csv\n",
      "<_io.TextIOWrapper name='data_prova/31-05-2023_10_53_20/ES_PM10.csv' mode='r' encoding='utf-8'>\n",
      "  network_countrycode network_localid    network_name network_namespace  \\\n",
      "0                  ES      NET_ES206A  CCAA Cantabria       ES.BDCA.AQD   \n",
      "1                  ES      NET_ES206A  CCAA Cantabria       ES.BDCA.AQD   \n",
      "2                  ES      NET_ES206A  CCAA Cantabria       ES.BDCA.AQD   \n",
      "3                  ES      NET_ES206A  CCAA Cantabria       ES.BDCA.AQD   \n",
      "4                  ES      NET_ES206A  CCAA Cantabria       ES.BDCA.AQD   \n",
      "\n",
      "                                    network_timezone pollutant  \\\n",
      "0  http://dd.eionet.europa.eu/vocabulary/aq/timez...      PM10   \n",
      "1  http://dd.eionet.europa.eu/vocabulary/aq/timez...      PM10   \n",
      "2  http://dd.eionet.europa.eu/vocabulary/aq/timez...      PM10   \n",
      "3  http://dd.eionet.europa.eu/vocabulary/aq/timez...      PM10   \n",
      "4  http://dd.eionet.europa.eu/vocabulary/aq/timez...      PM10   \n",
      "\n",
      "  samplingpoint_localid samplingpoint_namespace  samplingpoint_x  \\\n",
      "0     SP_39008001_10_49             ES.BDCA.AQD         -3.84194   \n",
      "1     SP_39008001_10_49             ES.BDCA.AQD         -3.84194   \n",
      "2     SP_39008001_10_49             ES.BDCA.AQD         -3.84194   \n",
      "3     SP_39008001_10_49             ES.BDCA.AQD         -3.84194   \n",
      "4     SP_39008001_10_49             ES.BDCA.AQD         -3.84194   \n",
      "\n",
      "   samplingpoint_y  ... station_namespace       value_datetime_begin  \\\n",
      "0         43.40444  ...       ES.BDCA.AQD  2023-05-30 04:00:00+01:00   \n",
      "1         43.40444  ...       ES.BDCA.AQD  2023-05-30 05:00:00+01:00   \n",
      "2         43.40444  ...       ES.BDCA.AQD  2023-05-30 06:00:00+01:00   \n",
      "3         43.40444  ...       ES.BDCA.AQD  2023-05-30 07:00:00+01:00   \n",
      "4         43.40444  ...       ES.BDCA.AQD  2023-05-30 08:00:00+01:00   \n",
      "\n",
      "          value_datetime_end    value_datetime_inserted  \\\n",
      "0  2023-05-30 05:00:00+01:00  2023-05-30 03:42:10+01:00   \n",
      "1  2023-05-30 06:00:00+01:00  2023-05-30 04:45:09+01:00   \n",
      "2  2023-05-30 07:00:00+01:00  2023-05-30 05:48:09+01:00   \n",
      "3  2023-05-30 08:00:00+01:00  2023-05-30 06:45:10+01:00   \n",
      "4  2023-05-30 09:00:00+01:00  2023-05-30 07:48:09+01:00   \n",
      "\n",
      "      value_datetime_updated value_numeric value_validity value_verification  \\\n",
      "0  2023-05-30 06:45:10+01:00          20.0              1                  3   \n",
      "1  2023-05-30 07:48:09+01:00          32.0              1                  3   \n",
      "2  2023-05-30 08:45:11+01:00          22.0              1                  3   \n",
      "3  2023-05-30 09:45:09+01:00          66.0              1                  3   \n",
      "4  2023-05-30 10:42:09+01:00          48.0              1                  3   \n",
      "\n",
      "  station_altitude  value_unit  \n",
      "0               16       ug/m3  \n",
      "1               16       ug/m3  \n",
      "2               16       ug/m3  \n",
      "3               16       ug/m3  \n",
      "4               16       ug/m3  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data_prova/31-05-2023_09_15_34/ES_PM10.csv'\n",
    "file_path = 'data_prova/31-05-2023_10_53_20/ES_PM10.csv'\n",
    "print(file_path)\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    print(file)\n",
    "    first_line = file.readline().strip()\n",
    "\n",
    "if not first_line.startswith('<!DOCTYPE html'): \n",
    "    #print(fileName,'exist')\n",
    "\n",
    "    df_temp = pd.read_csv(file_path)\n",
    "    print(df_temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('data_prova/31-05-2023_10_53_20/ES_PM10.csv', 'r', encoding='utf-8-sig') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Modify the content as needed\n",
    "\n",
    "with codecs.open('data_prova/31-05-2023_10_53_20/ES_PM10.csv', 'w', encoding='utf-8') as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def download_request(COUNTRIES= 'ES',\n",
    "                        POLLUTANTS= 'PM10',\n",
    "                        folder_out = 'data_prova'):\n",
    "    print ('-----------------------------------------------------------------------')\n",
    "    # Set download url\n",
    "    # https://discomap.eea.europa.eu/map/fme/AirQualityUTDExport.htm\n",
    "    ServiceUrl = \"http://discomap.eea.europa.eu/map/fme/latest\"\n",
    "\n",
    "\n",
    "    dir = datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\")\n",
    "\n",
    "    if not os.path.exists(os.path.join(folder_out, dir)):\n",
    "        if not os.path.exists(folder_out):\n",
    "            os.mkdir(folder_out)\n",
    "        os.mkdir(os.path.join(folder_out, dir))\n",
    "        print(dir,'directory created')\n",
    "        \n",
    "    for country in COUNTRIES:\n",
    "        for pollutant in POLLUTANTS:\n",
    "            fileName = \"%s_%s.csv\" % (country, pollutant)\n",
    "            downloadFile = '%s/%s_%s.csv' % (ServiceUrl, country, pollutant)\n",
    "            #Download and save to local path\n",
    "            print('Downloading: %s' % downloadFile )\n",
    "\n",
    "            file = requests.get(downloadFile).content\n",
    "            full_file = os.path.join(folder_out, dir, fileName)\n",
    "\t\t\t\n",
    "\n",
    "\n",
    "            '''with codecs.open(full_file, 'r', encoding='utf-8-sig') as file:\n",
    "                content = file.read()'''\n",
    "\n",
    "            # Modify the content as needed\n",
    "            with codecs.open(full_file, 'w', encoding='utf-8') as output:\n",
    "                output.write(file)\n",
    "\n",
    "\n",
    "\n",
    "            '''output = open(full_file, 'wb')\n",
    "            output.write(file)\n",
    "            output.close()'''\n",
    "            print ('Saved locally as: %s ' % full_file)\n",
    "            print ('-----')\n",
    "    print ('Download finished')\n",
    "    return dir\n",
    "\n",
    "dirr = download_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "31-05-2023_11_47_40 directory created\n",
      "Downloading: http://discomap.eea.europa.eu/map/fme/latest/ES_PM10.csv\n",
      "Saved locally as: data_prova\\31-05-2023_11_47_40\\ES_PM10.csv \n",
      "-----\n",
      "Download finished\n"
     ]
    }
   ],
   "source": [
    "def download_request(COUNTRIES=['ES'], POLLUTANTS=['PM10'], folder_out='data_prova'):\n",
    "    print('-----------------------------------------------------------------------')\n",
    "    # Set download url\n",
    "    # https://discomap.eea.europa.eu/map/fme/AirQualityUTDExport.htm\n",
    "    ServiceUrl = \"http://discomap.eea.europa.eu/map/fme/latest\"\n",
    "\n",
    "    dir = datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\")\n",
    "\n",
    "    if not os.path.exists(os.path.join(folder_out, dir)):\n",
    "        if not os.path.exists(folder_out):\n",
    "            os.mkdir(folder_out)\n",
    "        os.mkdir(os.path.join(folder_out, dir))\n",
    "        print(dir, 'directory created')\n",
    "\n",
    "    for country in COUNTRIES:\n",
    "        for pollutant in POLLUTANTS:\n",
    "            fileName = \"%s_%s.csv\" % (country, pollutant)\n",
    "            downloadFile = '%s/%s_%s.csv' % (ServiceUrl, country, pollutant)\n",
    "            # Download and save to local path\n",
    "            print('Downloading: %s' % downloadFile)\n",
    "\n",
    "            file_content = requests.get(downloadFile).content\n",
    "            file_content_str = file_content.decode('utf-8-sig')\n",
    "\n",
    "            full_file = os.path.join(folder_out, dir, fileName)\n",
    "\n",
    "            with open(full_file, 'w', encoding='utf-8') as output:\n",
    "                output.write(file_content_str)\n",
    "\n",
    "            print('Saved locally as: %s ' % full_file)\n",
    "            print('-----')\n",
    "    print('Download finished')\n",
    "    return dir\n",
    "\n",
    "dirr = download_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "31-05-2023_11_47_59 directory created\n",
      "Downloading: http://discomap.eea.europa.eu/map/fme/latest/ES_PM10.csv\n",
      "Saved locally as: data_prova\\31-05-2023_11_47_59\\ES_PM10.csv \n",
      "-----\n",
      "Download finished\n"
     ]
    }
   ],
   "source": [
    "def download_request(COUNTRIES=['ES'], POLLUTANTS=['PM10'], folder_out='data_prova'):\n",
    "    print('-----------------------------------------------------------------------')\n",
    "    # Set download url\n",
    "    # https://discomap.eea.europa.eu/map/fme/AirQualityUTDExport.htm\n",
    "    ServiceUrl = \"http://discomap.eea.europa.eu/map/fme/latest\"\n",
    "\n",
    "    dir = datetime.now().strftime(\"%d-%m-%Y_%H_%M_%S\")\n",
    "\n",
    "    if not os.path.exists(os.path.join(folder_out, dir)):\n",
    "        if not os.path.exists(folder_out):\n",
    "            os.mkdir(folder_out)\n",
    "        os.mkdir(os.path.join(folder_out, dir))\n",
    "        print(dir, 'directory created')\n",
    "\n",
    "    for country in COUNTRIES:\n",
    "        for pollutant in POLLUTANTS:\n",
    "            fileName = \"%s_%s.csv\" % (country, pollutant)\n",
    "            downloadFile = '%s/%s_%s.csv' % (ServiceUrl, country, pollutant)\n",
    "            # Download and save to local path\n",
    "            print('Downloading: %s' % downloadFile)\n",
    "\n",
    "            file_content = requests.get(downloadFile).content\n",
    "            file_content_str = file_content.decode('utf-8-sig')\n",
    "\n",
    "            full_file = os.path.join(folder_out, dir, fileName)\n",
    "\n",
    "            with codecs.open(full_file, 'w', encoding='utf-8') as output:\n",
    "                output.write(file_content_str)\n",
    "\n",
    "            print('Saved locally as: %s ' % full_file)\n",
    "            print('-----')\n",
    "    print('Download finished')\n",
    "    return dir\n",
    "\n",
    "dirr = download_request()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
