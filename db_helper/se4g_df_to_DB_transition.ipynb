{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected with  localhost\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "ip = '192.168.30.19'\n",
    "ip = 'localhost'\n",
    "conn = psycopg2.connect(\n",
    "    host = ip,\n",
    "    database = \"se4g\",\n",
    "    user = \"postgres\",\n",
    "    password = \"carIs3198\"\n",
    ")\n",
    "print('connected with ',ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(table_name, rows, conn, columns):\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Generate the SQL INSERT statement with specified columns\n",
    "    insert_statement = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))})\"\n",
    "\n",
    "    \n",
    "    rows = [\n",
    "        tuple(\n",
    "            val.strftime('%Y-%m-%d %H:%M:%S%z') if isinstance(val, datetime) else val\n",
    "            if val != '' else None  # Replace empty string with None for double precision columns\n",
    "            for val in row\n",
    "        )\n",
    "        for row in rows\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Execute the INSERT statement for each row\n",
    "    cur.executemany(insert_statement, rows)\n",
    "\n",
    "    # Commit the changes and close the cursor\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "\n",
    "\n",
    "def table_exists(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = '{table_name}')\")\n",
    "    exists = cur.fetchone()[0]\n",
    "    cur.close()\n",
    "    return exists\n",
    "\n",
    "\n",
    "# Update the final dataset\n",
    "def update_DB(new_rows, connection, table_name='se4g_prova', columns=None):\n",
    "    cur = connection.cursor()\n",
    "\n",
    "    # Generate the SQL SELECT statement\n",
    "    select_statement = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "    # Execute the SELECT statement\n",
    "    cur.execute(select_statement)\n",
    "\n",
    "    # Fetch all the results\n",
    "    results = cur.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    all_columns = [desc[0] for desc in cur.description]\n",
    "\n",
    "    # Use all columns if specific columns are not provided\n",
    "    if not columns:\n",
    "        columns = all_columns\n",
    "\n",
    "    # Convert the results to a set of tuples for efficient comparison\n",
    "    existing_data = {tuple(row) for row in results}\n",
    "\n",
    "    # Filter new_rows to only include rows not already present in the table\n",
    "    filtered_rows = [row for row in new_rows if tuple(row) not in existing_data]\n",
    "\n",
    "    if len(filtered_rows) == 0:\n",
    "        print(\"Nothing to update inside database\", table_name)\n",
    "    else:\n",
    "\n",
    "        # Execute the INSERT statement to add the filtered rows\n",
    "        insert_data(table_name, filtered_rows, connection, columns)\n",
    "        print(\"Database\", table_name, \"updated successfully\")\n",
    "\n",
    "    # Close the cursor\n",
    "    cur.close()\n",
    "\n",
    "    return filtered_rows\n",
    "\n",
    "\n",
    "countries = ['AD']\n",
    "pollutants = ['SO2']\n",
    "\n",
    "# Download and get the dataframe file name\n",
    "def download_DB(\n",
    "    COUNTRIES=countries,\n",
    "    POLLUTANTS=pollutants,\n",
    "    folder_out='data',\n",
    "    df_columns=[\n",
    "        'station_code',\n",
    "        'station_name',\n",
    "        'station_altitude',\n",
    "        'network_countrycode',\n",
    "        'pollutant',\n",
    "        'value_datetime_begin',\n",
    "        'value_datetime_end',\n",
    "        'value_datetime_updated',\n",
    "        'value_numeric',\n",
    "    ],\n",
    "    table_name='se4g_prova',\n",
    "    connection=conn,\n",
    "):\n",
    "    print('-----------------------------------------------------------------------')\n",
    "    # Set download url\n",
    "    # https://discomap.eea.europa.eu/map/fme/AirQualityUTDExport.htm\n",
    "    ServiceUrl = \"http://discomap.eea.europa.eu/map/fme/latest\"\n",
    "\n",
    "    # Create a cursor\n",
    "    cur = connection.cursor()\n",
    "\n",
    "    # Check if the table exists, create it if it doesn't\n",
    "    if not table_exists(table_name, connection):\n",
    "\n",
    "        data_type = ['VARCHAR',\n",
    "            'VARCHAR',\n",
    "            'FLOAT',\n",
    "            'CHAR(2)',\n",
    "            'VARCHAR',\n",
    "            'VARCHAR',\n",
    "            'VARCHAR',\n",
    "            'VARCHAR',\n",
    "            'FLOAT']\n",
    "        \n",
    "        column_definitions = [f\"{column} {data_type[i]}\" for i, column in enumerate(df_columns)]\n",
    "        create_table_statement = f\"CREATE TABLE {table_name} ({', '.join(column_definitions)})\"\n",
    "        cur.execute(create_table_statement)\n",
    "        conn.commit()\n",
    "\n",
    "    for country in COUNTRIES:\n",
    "        for pollutant in POLLUTANTS:\n",
    "            downloadFile = f\"{ServiceUrl}/{country}_{pollutant}.csv\"\n",
    "            # Download and save to local path\n",
    "            print('Downloading:', downloadFile)\n",
    "\n",
    "            file_content = requests.get(downloadFile).content\n",
    "            file_content_str = file_content.decode('utf-8-sig')\n",
    "\n",
    "            # Split the string into lines and split each line by comma (change delimiter as per your CSV format)\n",
    "            lines = file_content_str.splitlines()\n",
    "            lines = file_content_str.strip().split('\\n')\n",
    "\n",
    "            print(lines[0])\n",
    "\n",
    "            if not lines[0].startswith('<!DOCTYPE html'):\n",
    "\n",
    "                # Create a list of values to be inserted\n",
    "                data = [line.split(',') for line in lines]\n",
    "\n",
    "                # Get the column names from the CSV file\n",
    "                csv_columns = data[0]\n",
    "\n",
    "                # Create a dictionary to map CSV columns to indices\n",
    "                csv_column_dict = {col: index for index, col in enumerate(csv_columns)}\n",
    "                '''column_dict = {col: index for index, col in enumerate(df_columns)}'''\n",
    "\n",
    "\n",
    "                # Filter the data to include only the desired columns\n",
    "                '''filtered_data = [[row[column_dict[col]] for col in df_columns] for row in data[1:]]'''\n",
    "                filtered_data = [[row[csv_column_dict[col]] for col in df_columns] for row in data[1:]]\n",
    "                \n",
    "                new_rows = [tuple(row) for row in filtered_data]\n",
    "\n",
    "                print('Download finished and new_rows assembled')\n",
    "\n",
    "                print('Download finished and new_rows assembled')\n",
    "                print(new_rows[:5])\n",
    "\n",
    "                # Update the database table with new rows if not already present\n",
    "                updated_rows = update_DB(new_rows, connection, table_name, df_columns)\n",
    "\n",
    "                return updated_rows\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "\n",
    "\n",
    "download_DB()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table 'se4g_pollution_DB' exists: True\n",
      "already exist\n"
     ]
    }
   ],
   "source": [
    "table_name='se4g_prova'\n",
    "table_name='se4g_pollution_DB'\n",
    "\n",
    "def table_exists(table_name, conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE LOWER(table_name) = LOWER('{table_name}'))\")\n",
    "    exists = cur.fetchone()[0]\n",
    "    cur.close()\n",
    "    return exists\n",
    "\n",
    "if not table_exists(table_name, conn):\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    data_type = ['VARCHAR',\n",
    "                'VARCHAR',\n",
    "                'FLOAT',\n",
    "                'CHAR(2)',\n",
    "                'VARCHAR',\n",
    "                'VARCHAR',\n",
    "                'VARCHAR',\n",
    "                'VARCHAR',\n",
    "                'FLOAT']\n",
    "\n",
    "    df_columns=[\n",
    "        'station_code',\n",
    "        'station_name',\n",
    "        'station_altitude',\n",
    "        'network_countrycode',\n",
    "        'pollutant',\n",
    "        'value_datetime_begin',\n",
    "        'value_datetime_end',\n",
    "        'value_datetime_updated',\n",
    "        'value_numeric',\n",
    "    ]\n",
    "\n",
    "    column_definitions = [f\"{column} {data_type[i]}\" for i, column in enumerate(df_columns)]\n",
    "    create_table_statement = f\"CREATE TABLE {table_name} ({', '.join(column_definitions)})\"\n",
    "    print(create_table_statement)\n",
    "\n",
    "    cur.execute(create_table_statement)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    print('created')\n",
    "else:\n",
    "    exists = table_exists(table_name,conn)\n",
    "    print(f\"The table '{table_name}' exists: {exists}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_table_data(connection, source_table_name, destination_table_name):\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    # Truncate the destination table to remove existing data (optional)\n",
    "    cursor.execute(f\"TRUNCATE TABLE {destination_table_name};\")\n",
    "    \n",
    "    # Generate the SQL statement to copy data from the source table to the destination table\n",
    "    copy_data_query = f\"INSERT INTO {destination_table_name} SELECT * FROM {source_table_name};\"\n",
    "    \n",
    "    # Execute the COPY command\n",
    "    cursor.execute(copy_data_query)\n",
    "    \n",
    "    # Commit the changes\n",
    "    connection.commit()\n",
    "    \n",
    "    # Close the cursor\n",
    "    cursor.close()\n",
    "\n",
    "# Specify the names of the source table and destination table\n",
    "source_table_name = 'se4g_pollution'\n",
    "destination_table_name = 'se4g_pollution_DB'\n",
    "\n",
    "# Call the function to copy the data from the source table to the destination table\n",
    "copy_table_data(conn, source_table_name, destination_table_name)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
