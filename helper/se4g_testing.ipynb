{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from se4g_dir import set_the_working_directory\n",
    "from se4g_helper import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_connect_right_now(self):\n",
    "    conn = connect_right_now()\n",
    "    self.assertIsNotNone(conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_connect_with_sqlalchemy(self):\n",
    "    engine = connect_with_sqlalchemy()\n",
    "    self.assertIsNotNone(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_insert_data(self):\n",
    "    conn = connect_right_now()\n",
    "    columns = ['column1', 'column2']  # Replace with your column names\n",
    "    rows = [(1, 'data1'), (2, 'data2')]  # Replace with your sample rows\n",
    "    insert_data('test_table', rows, conn, columns)\n",
    "\n",
    "    # Now, fetch the inserted data and verify its correctness\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM test_table\")\n",
    "    inserted_data = cur.fetchall()\n",
    "\n",
    "    self.assertEqual(len(inserted_data), len(rows))\n",
    "    self.assertEqual(inserted_data, rows)\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_table_exists(self):\n",
    "    conn = connect_right_now()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Create a temporary table\n",
    "    cur.execute(\"CREATE TABLE temp_table (id SERIAL PRIMARY KEY, name VARCHAR)\")\n",
    "\n",
    "    # Check if the table exists\n",
    "    exists = table_exists('temp_table', conn)\n",
    "    self.assertTrue(exists)\n",
    "\n",
    "    # Drop the temporary table\n",
    "    cur.execute(\"DROP TABLE temp_table\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_update_DB(self):\n",
    "    conn = connect_right_now()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Create a temporary table\n",
    "    cur.execute(\"CREATE TABLE temp_table (id SERIAL PRIMARY KEY, name VARCHAR)\")\n",
    "\n",
    "    # Insert some initial data into the table\n",
    "    initial_data = [(1, 'data1'), (2, 'data2')]\n",
    "    insert_data('temp_table', initial_data, conn, ['id', 'name'])\n",
    "\n",
    "    # Define the new rows to be inserted\n",
    "    new_rows = [(3, 'data3'), (4, 'data4')]\n",
    "\n",
    "    # Call the update_DB() function\n",
    "    updated_rows = update_DB(new_rows, conn, 'temp_table', ['id', 'name'])\n",
    "\n",
    "    # Fetch the updated data\n",
    "    cur.execute(\"SELECT * FROM temp_table\")\n",
    "    updated_data = cur.fetchall()\n",
    "\n",
    "    # Verify the correctness of the updated data\n",
    "    expected_data = initial_data + updated_rows\n",
    "    self.assertEqual(len(updated_data), len(expected_data))\n",
    "    self.assertEqual(updated_data, expected_data)\n",
    "\n",
    "    # Drop the temporary table\n",
    "    cur.execute(\"DROP TABLE temp_table\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_update_DB_from_CSV(self):\n",
    "    conn = connect_right_now()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Create a temporary table\n",
    "    cur.execute(\"CREATE TABLE temp_table (id SERIAL PRIMARY KEY, name VARCHAR)\")\n",
    "\n",
    "    # Insert some initial data into the table\n",
    "    initial_data = [(1, 'data1'), (2, 'data2')]\n",
    "    insert_data('temp_table', initial_data, conn, ['id', 'name'])\n",
    "\n",
    "    # Create a new DataFrame representing the data from the CSV file\n",
    "    new_data = pd.DataFrame([(3, 'data3'), (4, 'data4')], columns=['id', 'name'])\n",
    "\n",
    "    # Call the update_DB_from_CSV() function\n",
    "    updated_data = update_DB_from_CSV(new_data, conn, 'temp_table', ['id', 'name'])\n",
    "\n",
    "    # Fetch the updated data\n",
    "    cur.execute(\"SELECT * FROM temp_table\")\n",
    "    updated_table = cur.fetchall()\n",
    "\n",
    "    # Verify the correctness of the updated data\n",
    "    expected_table = initial_data + updated_data\n",
    "    self.assertEqual(len(updated_table), len(expected_table))\n",
    "    self.assertEqual(updated_table, expected_table)\n",
    "\n",
    "    # Drop the temporary table\n",
    "    cur.execute(\"DROP TABLE temp_table\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_update_dashboard_DB_from_CSV(self):\n",
    "    conn = connect_right_now()\n",
    "    engine = connect_with_sqlalchemy()\n",
    "\n",
    "    # Create a temporary table for the dashboard\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"CREATE TABLE temp_dashboard (id SERIAL PRIMARY KEY, name VARCHAR)\")\n",
    "\n",
    "    # Insert some initial data into the dashboard table\n",
    "    initial_data = [(1, 'data1'), (2, 'data2')]\n",
    "    insert_data('temp_dashboard', initial_data, conn, ['id', 'name'])\n",
    "\n",
    "    # Create a new DataFrame representing the data from the CSV file\n",
    "    new_data = pd.DataFrame([(3, 'data3'), (4, 'data4')], columns=['id', 'name'])\n",
    "\n",
    "    # Call the update_dashboard_DB_from_CSV() function\n",
    "    updated_data = update_dashboard_DB_from_CSV(new_data, conn, engine, 'temp_dashboard', ['id', 'name'])\n",
    "\n",
    "    # Fetch the updated data from the dashboard table\n",
    "    cur.execute(\"SELECT * FROM temp_dashboard\")\n",
    "    updated_table = cur.fetchall()\n",
    "\n",
    "    # Verify the correctness of the updated data\n",
    "    expected_table = initial_data + updated_data\n",
    "    self.assertEqual(len(updated_table), len(expected_table))\n",
    "    self.assertEqual(updated_table, expected_table)\n",
    "\n",
    "    # Drop the temporary table\n",
    "    cur.execute(\"DROP TABLE temp_dashboard\")\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test download_request function\n",
    "def test_download_request():\n",
    "    COUNTRIES = ['AD', 'SE']\n",
    "    POLLUTANTS = ['PM10', 'NO2']\n",
    "    folder_out = 'test_data'\n",
    "    dir = download_request(COUNTRIES, POLLUTANTS, folder_out)\n",
    "    \n",
    "    assert os.path.exists(os.path.join(folder_out, dir))\n",
    "    assert len(os.listdir(os.path.join(folder_out, dir))) == len(COUNTRIES) * len(POLLUTANTS)\n",
    "\n",
    "# Test build_dataframe function\n",
    "def test_build_dataframe():\n",
    "    dir = 'test_dir'\n",
    "    COUNTRIES = ['AD', 'SE']\n",
    "    POLLUTANTS = ['PM10', 'NO2']\n",
    "    folder_out = 'test_data'\n",
    "    df_columns = ['pollutant', 'value_datetime_begin', 'value_numeric']\n",
    "    df = build_dataframe(dir, COUNTRIES, POLLUTANTS, folder_out, df_columns)\n",
    "    \n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    assert set(df.columns) == set(df_columns)\n",
    "    assert not df.empty\n",
    "\n",
    "# Test update_dataset function\n",
    "def test_update_dataset():\n",
    "    folder_out = 'test_data'\n",
    "    fileName = 'test_dataset.csv'\n",
    "    \n",
    "    # Create a dummy existing dataset\n",
    "    existing_data = pd.DataFrame({\n",
    "        'pollutant': ['PM10', 'PM2.5'],\n",
    "        'value_datetime_begin': ['2022-01-01 00:00:00', '2022-01-02 00:00:00'],\n",
    "        'value_numeric': [20, 30]\n",
    "    })\n",
    "    existing_data.to_csv(os.path.join(folder_out, fileName), index=False)\n",
    "    \n",
    "    # Create a new DataFrame with additional rows\n",
    "    new_data = pd.DataFrame({\n",
    "        'pollutant': ['NO2', 'NO2'],\n",
    "        'value_datetime_begin': ['2022-01-03 00:00:00', '2022-01-04 00:00:00'],\n",
    "        'value_numeric': [40, 50]\n",
    "    })\n",
    "    update_dataset(new_data, folder_out, fileName)\n",
    "    \n",
    "    # Check if the dataset is updated correctly\n",
    "    updated_data = pd.read_csv(os.path.join(folder_out, fileName))\n",
    "    assert len(updated_data) == len(existing_data) + len(new_data)\n",
    "    assert updated_data['value_datetime_begin'].max() == new_data['value_datetime_begin'].max()\n",
    "\n",
    "# Test update_dashboard_dataset function\n",
    "def test_update_dashboard_dataset():\n",
    "    folder_out = 'test_data'\n",
    "    fileName = 'test_dashboard_dataset.csv'\n",
    "    \n",
    "    # Create a dummy existing dataset\n",
    "    existing_data = pd.DataFrame({\n",
    "        'pollutant': ['PM10', 'PM2.5'],\n",
    "        'network_countrycode': ['AD', 'SE'],\n",
    "        'value_datetime_end': ['2022-01-01 00:00:00+00:00', '2022-01-02 00:00:00+00:00'],\n",
    "        'value_numeric': [20, 30]\n",
    "    })\n",
    "    existing_data.to_csv(os.path.join(folder_out, fileName), index=False)\n",
    "    \n",
    "    # Create a new DataFrame with additional rows\n",
    "    new_data = pd.DataFrame({\n",
    "        'pollutant': ['NO2', 'NO2'],\n",
    "        'network_countrycode': ['AD', 'SE'],\n",
    "        'value_datetime_end': ['2022-01-03 00:00:00+00:00', '2022-01-04 00:00:00+00:00'],\n",
    "        'value_numeric': [40, 50]\n",
    "    })\n",
    "    update_dashboard_dataset(new_data, folder_out)\n",
    "    \n",
    "    # Check if the dataset is updated correctly\n",
    "    updated_data = pd.read_csv(os.path.join(folder_out, fileName))\n",
    "    assert len(updated_data) == len(existing_data) + len(new_data)\n",
    "    assert updated_data['value_datetime_end'].max() == new_data['value_datetime_end'].max()\n",
    "\n",
    "# Test update_data function\n",
    "def test_update_data():\n",
    "    # Create a dummy directory and files\n",
    "    dir = 'test_dir'\n",
    "    COUNTRIES = ['AD', 'SE']\n",
    "    POLLUTANTS = ['PM10', 'NO2']\n",
    "    folder_out = 'test_data'\n",
    "    os.makedirs(os.path.join(folder_out, dir), exist_ok=True)\n",
    "    for country in COUNTRIES:\n",
    "        for pollutant in POLLUTANTS:\n",
    "            fileName = \"%s_%s.csv\" % (country, pollutant)\n",
    "            file_path = os.path.join(folder_out, dir, fileName)\n",
    "            df = pd.DataFrame({\n",
    "                'pollutant': [pollutant],\n",
    "                'value_datetime_begin': [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")],\n",
    "                'value_numeric': [100]\n",
    "            })\n",
    "            df.to_csv(file_path, index=False)\n",
    "    \n",
    "    # Execute the update process\n",
    "    update_data()\n",
    "    \n",
    "    # Check if the datasets are updated correctly\n",
    "    dataset_file = os.path.join(folder_out, 'se4g_pollution_dataset.csv')\n",
    "    dashboard_file = os.path.join(folder_out, 'se4g_dashboard_dataset.csv')\n",
    "    assert os.path.isfile(dataset_file)\n",
    "    assert os.path.isfile(dashboard_file)\n",
    "    dataset = pd.read_csv(dataset_file)\n",
    "    dashboard = pd.read_csv(dashboard_file)\n",
    "    assert len(dataset) == len(COUNTRIES) * len(POLLUTANTS)\n",
    "    assert len(dashboard) == len(COUNTRIES) * len(POLLUTANTS)\n",
    "\n",
    "# Run the test cases\n",
    "test_download_request()\n",
    "test_build_dataframe()\n",
    "test_update_dataset()\n",
    "test_update_dashboard_dataset()\n",
    "test_update_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Login & Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import patch\n",
    "from io import StringIO\n",
    "from register_login import Register, Login\n",
    "\n",
    "class TestRegisterLogin(unittest.TestCase):\n",
    "\n",
    "    def test_new_user(self):\n",
    "        register = Register()\n",
    "\n",
    "        # Patching input() to simulate user input\n",
    "        with patch('builtins.input', side_effect=['JohnDoe', 'password123']):\n",
    "            register._new_user()\n",
    "\n",
    "        # Assert that the user is added to the register_list\n",
    "        self.assertEqual(register.register_list['JohnDoe'], 'password123')\n",
    "\n",
    "    def test_remove_registration(self):\n",
    "        register = Register()\n",
    "        register.register_list = {'JohnDoe': 'password123'}\n",
    "\n",
    "        # Remove an existing registration\n",
    "        register.remove_registration('JohnDoe', 'password123')\n",
    "        self.assertNotIn('JohnDoe', register.register_list)\n",
    "\n",
    "        # Attempt to remove a non-existent registration\n",
    "        register.remove_registration('JaneDoe', 'password456')\n",
    "        self.assertNotIn('JaneDoe', register.register_list)\n",
    "\n",
    "    def test_review_registrations(self):\n",
    "        register = Register()\n",
    "        register.register_list = {'JohnDoe': 'password123', 'JaneDoe': 'password456'}\n",
    "\n",
    "        # Patching the print() function to capture the output\n",
    "        with patch('sys.stdout', new=StringIO()) as fake_output:\n",
    "            register._review_registrations()\n",
    "            output = fake_output.getvalue()\n",
    "\n",
    "        # Assert that the review of registrations is displayed correctly\n",
    "        self.assertIn('JohnDoe', output)\n",
    "        self.assertIn('JaneDoe', output)\n",
    "\n",
    "    def test_check_credentials(self):\n",
    "        login = Login()\n",
    "        login.user_list = {'JohnDoe': 'password123'}\n",
    "\n",
    "        # Check with correct credentials\n",
    "        self.assertTrue(login.check_credentials('JohnDoe', 'password123'))\n",
    "\n",
    "        # Check with incorrect password\n",
    "        self.assertFalse(login.check_credentials('JohnDoe', 'password456'))\n",
    "\n",
    "        # Check with non-existent user\n",
    "        self.assertFalse(login.check_credentials('JaneDoe', 'password123'))\n",
    "\n",
    "    # Write test cases for the remaining functions in the Login class...\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard Creation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import patch, MagicMock\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from descriptive_stats import DescriptiveStats\n",
    "\n",
    "class TestDescriptiveStats(unittest.TestCase):\n",
    "\n",
    "    @patch('descriptive_stats.connect_right_now')\n",
    "    def test_create_df_from_table(self, mock_connect_right_now):\n",
    "        # Mock the database connection and cursor\n",
    "        mock_cursor = MagicMock()\n",
    "        mock_conn = MagicMock()\n",
    "        mock_conn.cursor.return_value = mock_cursor\n",
    "\n",
    "        # Mock the execute and fetch methods\n",
    "        mock_cursor.fetchall.return_value = [('A', 1), ('B', 2)]\n",
    "        mock_cursor.description = [('col1',), ('col2',)]\n",
    "\n",
    "        # Instantiate the DescriptiveStats class\n",
    "        descriptive_stats = DescriptiveStats()\n",
    "\n",
    "        # Mock the create_df_from_table method and assert the result\n",
    "        with patch.object(descriptive_stats, 'create_df_from_table') as mock_create_df:\n",
    "            mock_create_df.return_value = pd.DataFrame([('A', 1), ('B', 2)], columns=['col1', 'col2'])\n",
    "            df = descriptive_stats.create_df_from_table('table_name')\n",
    "\n",
    "        # Assert that the mock methods were called correctly\n",
    "        mock_connect_right_now.assert_called_once()\n",
    "        mock_conn.cursor.assert_called_once()\n",
    "        mock_cursor.execute.assert_called_once_with('SELECT * FROM table_name;')\n",
    "        mock_cursor.fetchall.assert_called_once()\n",
    "        mock_cursor.close.assert_called_once()\n",
    "        mock_conn.close.assert_called_once()\n",
    "\n",
    "        # Assert the DataFrame result\n",
    "        expected_df = pd.DataFrame([('A', 1), ('B', 2)], columns=['col1', 'col2'])\n",
    "        pd.testing.assert_frame_equal(df, expected_df)\n",
    "\n",
    "    def test_update_pollutants(self):\n",
    "        descriptive_stats = DescriptiveStats()\n",
    "        descriptive_stats.df_pollutant = pd.DataFrame({\n",
    "            'station_code': ['A', 'B', 'C'],\n",
    "            'pollutant': ['P1', 'P2', 'P1']\n",
    "        })\n",
    "        descriptive_stats.df_station = pd.DataFrame({\n",
    "            'station_code': ['A', 'B', 'C'],\n",
    "            'network_countrycode': ['Country1', 'Country2', 'Country1']\n",
    "        })\n",
    "\n",
    "        descriptive_stats.country_dropdown.value = 'Country1'\n",
    "        descriptive_stats.update_pollutants(None)\n",
    "\n",
    "        self.assertEqual(descriptive_stats.pollutant_dropdown.options, ['P1'])\n",
    "\n",
    "        descriptive_stats.country_dropdown.value = 'Country2'\n",
    "        descriptive_stats.update_pollutants(None)\n",
    "\n",
    "        self.assertEqual(descriptive_stats.pollutant_dropdown.options, ['P2'])\n",
    "\n",
    "    @patch('sys.stdout', new_callable=StringIO)\n",
    "    def test_update_statistics(self, mock_stdout):\n",
    "        descriptive_stats = DescriptiveStats()\n",
    "        descriptive_stats.df_pollutant = pd.DataFrame({\n",
    "            'station_code': ['A', 'B', 'C'],\n",
    "            'pollutant': ['P1', 'P2', 'P1'],\n",
    "            'value_numeric': [10, 20, 30]\n",
    "        })\n",
    "        descriptive_stats.df_station = pd.DataFrame({\n",
    "            'station_code': ['A', 'B', 'C'],\n",
    "            'network_countrycode': ['Country1', 'Country2', 'Country1']\n",
    "        }) \n",
    "\n",
    "        descriptive_stats.country_dropdown.value = 'Country1'\n",
    "        descriptive_stats.pollutant_dropdown.value = 'P1'\n",
    "        descriptive_stats.update_statistics(None)\n",
    "\n",
    "        output = mock_stdout.getvalue().strip()\n",
    "        expected_output = \"Mean: 20.00\\nMax: 30\\nMin: 10\"\n",
    "        self.assertEqual(output, expected_output)\n",
    "\n",
    "    # Write test cases for the remaining functions in the DescriptiveStats class...\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test download_request function\n",
    "def test_download_request():\n",
    "    COUNTRIES = ['AD', 'SE']\n",
    "    POLLUTANTS = ['PM10', 'NO2']\n",
    "    folder_out = 'test_data'\n",
    "    dir = download_request(COUNTRIES, POLLUTANTS, folder_out)\n",
    "    \n",
    "    assert os.path.exists(os.path.join(folder_out, dir))\n",
    "    assert len(os.listdir(os.path.join(folder_out, dir))) == len(COUNTRIES) * len(POLLUTANTS)\n",
    "\n",
    "# Test build_dataframe function\n",
    "def test_build_dataframe():\n",
    "    dir = 'test_dir'\n",
    "    COUNTRIES = ['AD', 'SE']\n",
    "    POLLUTANTS = ['PM10', 'NO2']\n",
    "    folder_out = 'test_data'\n",
    "    df_columns = ['pollutant', 'value_datetime_begin', 'value_numeric']\n",
    "    df = build_dataframe(dir, COUNTRIES, POLLUTANTS, folder_out, df_columns)\n",
    "    \n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    assert set(df.columns) == set(df_columns)\n",
    "    assert not df.empty\n",
    "\n",
    "# Test update_dataset function\n",
    "def test_update_dataset():\n",
    "    folder_out = 'test_data'\n",
    "    fileName = 'test_dataset.csv'\n",
    "    \n",
    "    # Create a dummy existing dataset\n",
    "    existing_data = pd.DataFrame({\n",
    "        'pollutant': ['PM10', 'PM2.5'],\n",
    "        'value_datetime_begin': ['2022-01-01 00:00:00', '2022-01-02 00:00:00'],\n",
    "        'value_numeric': [20, 30]\n",
    "    })\n",
    "    existing_data.to_csv(os.path.join(folder_out, fileName), index=False)\n",
    "    \n",
    "    # Create a new DataFrame with additional rows\n",
    "    new_data = pd.DataFrame({\n",
    "        'pollutant': ['NO2', 'NO2'],\n",
    "        'value_datetime_begin': ['2022-01-03 00:00:00', '2022-01-04 00:00:00'],\n",
    "        'value_numeric': [40, 50]\n",
    "    })\n",
    "    update_dataset(new_data, folder_out, fileName)\n",
    "    \n",
    "    # Check if the dataset is updated correctly\n",
    "    updated_data = pd.read_csv(os.path.join(folder_out, fileName))\n",
    "    assert len(updated_data) == len(existing_data) + len(new_data)\n",
    "    assert updated_data['value_datetime_begin'].max() == new_data['value_datetime_begin'].max()\n",
    "\n",
    "# Test update_dashboard_dataset function\n",
    "def test_update_dashboard_dataset():\n",
    "    folder_out = 'test_data'\n",
    "    fileName = 'test_dashboard_dataset.csv'\n",
    "    \n",
    "    # Create a dummy existing dataset\n",
    "    existing_data = pd.DataFrame({\n",
    "        'pollutant': ['PM10', 'PM2.5'],\n",
    "        'network_countrycode': ['AD', 'SE'],\n",
    "        'value_datetime_end': ['2022-01-01 00:00:00+00:00', '2022-01-02 00:00:00+00:00'],\n",
    "        'value_numeric': [20, 30]\n",
    "    })\n",
    "    existing_data.to_csv(os.path.join(folder_out, fileName), index=False)\n",
    "    \n",
    "    # Create a new DataFrame with additional rows\n",
    "    new_data = pd.DataFrame({\n",
    "        'pollutant': ['NO2', 'NO2'],\n",
    "        'network_countrycode': ['AD', 'SE'],\n",
    "        'value_datetime_end': ['2022-01-03 00:00:00+00:00', '2022-01-04 00:00:00+00:00'],\n",
    "        'value_numeric': [40, 50]\n",
    "    })\n",
    "    update_dashboard_dataset(new_data, folder_out)\n",
    "    \n",
    "    # Check if the dataset is updated correctly\n",
    "    updated_data = pd.read_csv(os.path.join(folder_out, fileName))\n",
    "    assert len(updated_data) == len(existing_data) + len(new_data)\n",
    "    assert updated_data['value_datetime_end'].max() == new_data['value_datetime_end'].max()\n",
    "\n",
    "# Test update_data function\n",
    "def test_update_data():\n",
    "    # Create a dummy directory and files\n",
    "    dir = 'test_dir'\n",
    "    COUNTRIES = ['AD', 'SE']\n",
    "    POLLUTANTS = ['PM10', 'NO2']\n",
    "    folder_out = 'test_data'\n",
    "    os.makedirs(os.path.join(folder_out, dir), exist_ok=True)\n",
    "    for country in COUNTRIES:\n",
    "        for pollutant in POLLUTANTS:\n",
    "            fileName = \"%s_%s.csv\" % (country, pollutant)\n",
    "            file_path = os.path.join(folder_out, dir, fileName)\n",
    "            df = pd.DataFrame({\n",
    "                'pollutant': [pollutant],\n",
    "                'value_datetime_begin': [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")],\n",
    "                'value_numeric': [100]\n",
    "            })\n",
    "            df.to_csv(file_path, index=False)\n",
    "    \n",
    "    # Execute the update process\n",
    "    update_data()\n",
    "    \n",
    "    # Check if the datasets are updated correctly\n",
    "    dataset_file = os.path.join(folder_out, 'se4g_pollution_dataset.csv')\n",
    "    dashboard_file = os.path.join(folder_out, 'se4g_dashboard_dataset.csv')\n",
    "    assert os.path.isfile(dataset_file)\n",
    "    assert os.path.isfile(dashboard_file)\n",
    "    dataset = pd.read_csv(dataset_file)\n",
    "    dashboard = pd.read_csv(dashboard_file)\n",
    "    assert len(dataset) == len(COUNTRIES) * len(POLLUTANTS)\n",
    "    assert len(dashboard) == len(COUNTRIES) * len(POLLUTANTS)\n",
    "\n",
    "# Run the test cases\n",
    "test_download_request()\n",
    "test_build_dataframe()\n",
    "test_update_dataset()\n",
    "test_update_dashboard_dataset()\n",
    "test_update_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import patch\n",
    "from dashboard import Dashboard\n",
    "\n",
    "class DashboardTestCase(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        # Set up the test data and initialize the Dashboard instance\n",
    "        cls.table_name = 'test_table'\n",
    "        cls.dashboard = Dashboard(table_name=cls.table_name)\n",
    "\n",
    "    def test_load_data(self):\n",
    "        # Mock the connect_right_now function and the cursor object\n",
    "        with patch('dashboard.connect_right_now') as mock_connect:\n",
    "            mock_cursor = mock_connect.return_value.cursor.return_value\n",
    "\n",
    "            # Set up the mock cursor to return test data\n",
    "            test_data = [\n",
    "                (1, '20210601', 'SO2', 'Country A', 10),\n",
    "                (2, '20210601', 'CO', 'Country B', 5),\n",
    "                (3, '20210602', 'SO2', 'Country C', 8),\n",
    "            ]\n",
    "            mock_cursor.fetchall.return_value = test_data\n",
    "            mock_cursor.description = [('id',), ('month_day',), ('pollutant',), ('country',), ('value_numeric_mean',)]\n",
    "\n",
    "            # Call the load_data method\n",
    "            self.dashboard.load_data()\n",
    "\n",
    "            # Verify that the data was loaded correctly into the DataFrame\n",
    "            expected_columns = ['id', 'month_day', 'pollutant', 'country', 'value_numeric_mean', 'time_series', 'month_day_date']\n",
    "            self.assertListEqual(list(self.dashboard.df.columns), expected_columns)\n",
    "            self.assertEqual(len(self.dashboard.df), len(test_data))\n",
    "            self.assertEqual(self.dashboard.df['pollutant'].nunique(), 2)\n",
    "            self.assertEqual(self.dashboard.df['country'].nunique(), 3)\n",
    "\n",
    "    def test_create_dashboard(self):\n",
    "        # Call the create_dashboard method\n",
    "        self.dashboard.create_dashboard()\n",
    "\n",
    "        # Verify that the layout was created successfully\n",
    "        self.assertIsNotNone(self.dashboard.app.layout)\n",
    "        # Add additional assertions as needed\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import patch, MagicMock\n",
    "from interactive import Interactive\n",
    "\n",
    "class InteractiveTestCase(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Create mock DataFrames for pollutants and stations\n",
    "        self.df_pollutant = MagicMock()\n",
    "        self.df_station = MagicMock()\n",
    "\n",
    "        # Initialize the Interactive instance with mock DataFrames\n",
    "        self.interactive = Interactive(df_pollutant=self.df_pollutant, df_station=self.df_station)\n",
    "\n",
    "    @patch('interactive.widgets')\n",
    "    def test_select_pollutant(self, mock_widgets):\n",
    "        # Mock the Dropdown widget and its display method\n",
    "        mock_dropdown = mock_widgets.Dropdown.return_value\n",
    "        mock_dropdown.options = ['SO2', 'NO2']\n",
    "        mock_display = mock_widgets.display\n",
    "\n",
    "        # Call the select_pollutant method\n",
    "        result = self.interactive.select_pollutant()\n",
    "\n",
    "        # Verify that the Dropdown widget was created and displayed\n",
    "        mock_widgets.Dropdown.assert_called_with(\n",
    "            options=['SO2', 'NO2'],\n",
    "            description='Select pollutant:',\n",
    "            layout=mock_widgets.Layout(width='250px'),\n",
    "            style={'description_width': 'initial', 'min-width': '250px', 'font-size': '10pt'}\n",
    "        )\n",
    "        mock_display.assert_called_with(mock_dropdown)\n",
    "\n",
    "        # Verify that the returned result is the Dropdown widget\n",
    "        self.assertEqual(result, mock_dropdown)\n",
    "\n",
    "    @patch('interactive.widgets')\n",
    "    def test_select_date(self, mock_widgets):\n",
    "        # Mock the Dropdown widget and its display method\n",
    "        mock_dropdown = mock_widgets.Dropdown.return_value\n",
    "        mock_dropdown.options = ['2023-01-01', '2023-01-02']\n",
    "        mock_display = mock_widgets.display\n",
    "\n",
    "        # Call the select_date method\n",
    "        result = self.interactive.select_date()\n",
    "\n",
    "        # Verify that the Dropdown widget was created and displayed\n",
    "        mock_widgets.Dropdown.assert_called_with(\n",
    "            options=['2023-01-01', '2023-01-02'],\n",
    "            description='Select date:',\n",
    "            layout=mock_widgets.Layout(width='250px'),\n",
    "            style={'description_width': 'initial', 'min-width': '250px', 'font-size': '10pt'}\n",
    "        )\n",
    "        mock_display.assert_called_with(mock_dropdown)\n",
    "\n",
    "        # Verify that the returned result is the Dropdown widget\n",
    "        self.assertEqual(result, mock_dropdown)\n",
    "\n",
    "    @patch('interactive.figure')\n",
    "    @patch('interactive.output_notebook')\n",
    "    @patch('interactive.show')\n",
    "    def test_create_bokeh_plot(self, mock_show, mock_output_notebook, mock_figure):\n",
    "        # Mock the DataFrame and Bokeh objects\n",
    "        df_selected = MagicMock()\n",
    "        df_filtered = MagicMock()\n",
    "        source = MagicMock()\n",
    "        p = mock_figure.return_value\n",
    "\n",
    "        # Set up the mock objects and their behaviors\n",
    "        self.df_pollutant.__getitem__.return_value = df_selected\n",
    "        self.df_station.merge.return_value = df_filtered\n",
    "        mock_figure.return_value = p\n",
    "        p.line.return_value = None\n",
    "\n",
    "        # Call the create_bokeh_plot method\n",
    "        self.interactive.create_bokeh_plot(selected_pollutant='SO2', selected_date='2023-01-01')\n",
    "\n",
    "        # Verify the expected interactions\n",
    "        self.df_pollutant.__getitem__.assert_called_with(\n",
    "            (self.df_pollutant['pollutant'] == 'SO2') &\n",
    "            (self.df_pollutant['value_datetime_begin'].dt.date == '2023-01-01')\n",
    "        )\n",
    "        self.df_station.merge.assert_called_with(self.df_selected, on='station_code')\n",
    "        p.line.assert_called_with(x='value_datetime_begin', y='value_numeric', source=source, line_color=color, legend_label=country)\n",
    "        mock_output_notebook.assert_called_once()\n",
    "        mock_show.assert_called_with(p)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
